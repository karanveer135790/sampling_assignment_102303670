# ğŸ“˜ Sampling Techniques on Imbalanced Dataset â€“ Machine Learning Assignment

This project is completed as part of Predictive Analytics (UCS654) coursework at Thapar Institute of Engineering and Technology in collaboration with Coursera Guided Learning.

The objective of this assignment is to study the importance of sampling techniques for handling imbalanced datasets and to analyze how different sampling strategies affect the performance of various machine learning models.

------------------------------------------------------------

ğŸ¯ Objective

In many real-world problems like fraud detection, datasets are highly imbalanced where one class contains significantly more samples than the other. This imbalance causes machine learning models to become biased towards the majority class and perform poorly on the minority class.

The goals of this assignment are:

â€¢ Balance the dataset  
â€¢ Apply five sampling techniques  
â€¢ Train five machine learning models  
â€¢ Compare model accuracy  
â€¢ Identify which sampling method performs best  

------------------------------------------------------------

ğŸ“‚ Dataset

Dataset Used: Credit Card Fraud Detection Dataset  
File: Creditcard_data.csv  

This dataset contains transaction records classified into:
â€¢ Class 0 â†’ Normal transactions  
â€¢ Class 1 â†’ Fraud transactions  

The dataset is highly imbalanced, making it ideal for testing sampling techniques.

------------------------------------------------------------

âš™ï¸ Methodology

Step 1 â€“ Data Loading  
The dataset was loaded using pandas and basic inspection was performed.

Step 2 â€“ Train-Test Split  
Data was split into:
â€¢ 80% Training data  
â€¢ 20% Testing data  

Step 3 â€“ Apply Sampling Techniques  
Five sampling techniques were used to balance the training data:

1. Random Oversampling  
2. Random Undersampling  
3. SMOTE  
4. SMOTE + ENN  
5. SMOTE + Tomek Links  

These methods either increase minority samples or reduce majority samples to create balanced class distribution.

------------------------------------------------------------

ğŸ¤– Machine Learning Models Used

Five classifiers were trained on each balanced dataset:

M1 â€“ Logistic Regression  
M2 â€“ Decision Tree  
M3 â€“ K-Nearest Neighbors (KNN)  
M4 â€“ Random Forest  
M5 â€“ Support Vector Machine (SVM)  

------------------------------------------------------------

ğŸ§ª Experiments

Each sampling technique was applied to each machine learning model.

Total experiments performed:

5 Sampling Methods Ã— 5 Models = 25 Experiments

For every combination, accuracy was calculated using the test dataset.

------------------------------------------------------------

ğŸ“Š Results

The results were stored in a comparison table showing accuracy values for every model and sampling technique.

Example format:

                Sampling1  Sampling2  Sampling3  Sampling4  Sampling5
M1 (LR)           xx         xx         xx         xx         xx
M2 (DT)           xx         xx         xx         xx         xx
M3 (KNN)          xx         xx         xx         xx         xx
M4 (RF)           xx         xx         xx         xx         xx
M5 (SVM)          xx         xx         xx         xx         xx

A heatmap visualization was also created to easily compare performance.

------------------------------------------------------------

âœ… Observations

â€¢ Models trained on imbalanced data performed poorly  
â€¢ Sampling improved minority class prediction  
â€¢ Oversampling techniques generally performed better than undersampling  
â€¢ SMOTE and hybrid techniques gave more stable results  
â€¢ Random Forest and SVM achieved higher accuracy compared to other models  

------------------------------------------------------------

ğŸ† Conclusion

This assignment demonstrates that sampling plays a very important role when working with imbalanced datasets. Balancing the dataset significantly improves model performance and prediction accuracy. Among different techniques, SMOTE-based methods often provided better results.

Therefore, selecting the right sampling strategy is essential for building reliable machine learning models on imbalanced data.

------------------------------------------------------------

ğŸ› ï¸ Technologies Used

â€¢ Python  
â€¢ Pandas  
â€¢ NumPy  
â€¢ Scikit-learn  
â€¢ Imbalanced-learn  
â€¢ Matplotlib  
â€¢ Seaborn  

------------------------------------------------------------

ğŸ“ Repository Structure

Sampling_Assignment/
â”‚â”€â”€ sampling.ipynb
â”‚â”€â”€ Creditcard_data.csv
â”‚â”€â”€ README.md

------------------------------------------------------------

ğŸš€ How to Run

Install dependencies:

pip install pandas numpy scikit-learn imbalanced-learn seaborn matplotlib

Then run:

sampling.ipynb

------------------------------------------------------------

ğŸ‘¨â€ğŸ’» Author

Karanveer Singh Saini  
UCS654 â€“ Predictive Analytics  
Thapar Institute of Engineering and Technology  

------------------------------------------------------------

#TIET  
#ThaparUniversity  
#ThaparOutcomeBasedLearning  
#ThaparCoursera  
#Coursera  
#MachineLearning  
#Sampling  
#ImbalancedLearning  
#PredictiveAnalytics
